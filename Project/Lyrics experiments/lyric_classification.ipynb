{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "53306684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from sklearn import feature_selection, feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "import collections\n",
    "import pathlib\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as df\n",
    "import os\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a881b4",
   "metadata": {},
   "source": [
    "## Text preprocessing: stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "072db433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this text preprocessor function was originally written by Mauro Di Pietro\n",
    "\n",
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    # clean (convert to lowercase and remove punctuations and   \n",
    "    # characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "id": "0c6dbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting through and extracting clustered files from their corresponding folders\n",
    "# i.e. path = '/Users/alina/desktop/475/proj/dataset/Lyrics/Cluster*/[corresponding mood folders]/*.txt'\n",
    "def sort_files(path):\n",
    "    results = defaultdict(list)\n",
    "    for folder in Path(path).iterdir():\n",
    "        for file in folder.iterdir():\n",
    "            with open(file, \"r\") as file_open:\n",
    "                results[\"mood_file\"].append(file)\n",
    "                results[\"filename\"].append(file.name)\n",
    "                results[\"cluster\"].append(path.name)\n",
    "                results[\"mood\"].append(folder.name)\n",
    "                results[\"text\"].append(file_open.read())\n",
    "        df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "9ba17506",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/Users/alina/desktop/475/proj/dataset/Lyrics\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for folder in Path(p).iterdir():\n",
    "    if os.path.isdir(folder):\n",
    "        temp = sort_files(folder)\n",
    "        df = pd.concat([df, temp])\n",
    "\n",
    "df = df.sort_values(\"filename\")\n",
    "df.to_csv('lyric_bag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "745ccafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lyric_bag.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421cb72",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "5132a287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood_file</th>\n",
       "      <th>filename</th>\n",
       "      <th>cluster</th>\n",
       "      <th>mood</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/alina/desktop/475/proj/dataset/Lyrics/C...</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Cluster1</td>\n",
       "      <td>Boisterous</td>\n",
       "      <td>Mama he treats your daughter mean \\nMama he tr...</td>\n",
       "      <td>mama treat daughter mean mama treat daughter m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/alina/desktop/475/proj/dataset/Lyrics/C...</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Cluster1</td>\n",
       "      <td>Boisterous</td>\n",
       "      <td>I plopped down in my easy chair and turned on ...</td>\n",
       "      <td>plopped easy chair turned channel 2 bad gunsli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/alina/desktop/475/proj/dataset/Lyrics/C...</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>Cluster1</td>\n",
       "      <td>Boisterous</td>\n",
       "      <td>Back in black \\nI hit the sack \\nIt's been too...</td>\n",
       "      <td>back black hit sack long im glad back yes im l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/alina/desktop/475/proj/dataset/Lyrics/C...</td>\n",
       "      <td>007.txt</td>\n",
       "      <td>Cluster1</td>\n",
       "      <td>Boisterous</td>\n",
       "      <td>Woo, I gave you my money, I gave you my time.\\...</td>\n",
       "      <td>woo gave money gave time wanna hurt girl serio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/alina/desktop/475/proj/dataset/Lyrics/C...</td>\n",
       "      <td>008.txt</td>\n",
       "      <td>Cluster1</td>\n",
       "      <td>Boisterous</td>\n",
       "      <td>Is it my imagination \\nOr have I finally found...</td>\n",
       "      <td>imagination finally found something worth livi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mood_file filename   cluster  \\\n",
       "0  /Users/alina/desktop/475/proj/dataset/Lyrics/C...  001.txt  Cluster1   \n",
       "1  /Users/alina/desktop/475/proj/dataset/Lyrics/C...  003.txt  Cluster1   \n",
       "2  /Users/alina/desktop/475/proj/dataset/Lyrics/C...  004.txt  Cluster1   \n",
       "3  /Users/alina/desktop/475/proj/dataset/Lyrics/C...  007.txt  Cluster1   \n",
       "4  /Users/alina/desktop/475/proj/dataset/Lyrics/C...  008.txt  Cluster1   \n",
       "\n",
       "         mood                                               text  \\\n",
       "0  Boisterous  Mama he treats your daughter mean \\nMama he tr...   \n",
       "1  Boisterous  I plopped down in my easy chair and turned on ...   \n",
       "2  Boisterous  Back in black \\nI hit the sack \\nIt's been too...   \n",
       "3  Boisterous  Woo, I gave you my money, I gave you my time.\\...   \n",
       "4  Boisterous  Is it my imagination \\nOr have I finally found...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  mama treat daughter mean mama treat daughter m...  \n",
       "1  plopped easy chair turned channel 2 bad gunsli...  \n",
       "2  back black hit sack long im glad back yes im l...  \n",
       "3  woo gave money gave time wanna hurt girl serio...  \n",
       "4  imagination finally found something worth livi...  "
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, \n",
    "          lst_stopwords=lst_stopwords))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b460ae",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "6f9a4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458, 2) (306, 2)\n"
     ]
    }
   ],
   "source": [
    "text = pd.DataFrame()\n",
    "\n",
    "text['cluster'] = df['cluster']\n",
    "text['text_clean'] = df['text_clean']\n",
    "\n",
    "#df_train, df_test = model_selection.train_test_split(text, test_size=0.3)\n",
    "df_train, df_test = model_selection.train_test_split(text, test_size=0.4)\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "7f2cd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df_train['text_clean']\n",
    "train_y = df_train['cluster']\n",
    "\n",
    "test_X = df_test['text_clean']\n",
    "test_y = df_test['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "615bb2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 458, n_features: 6557\n"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train_tf = tf_idf.fit_transform(train_X)\n",
    "X_train_tf = tf_idf.transform(train_X)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "id": "27ccbc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 306, n_features: 6557\n"
     ]
    }
   ],
   "source": [
    "X_test_tf = tf_idf.transform(test_X)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "db73ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b863b91",
   "metadata": {},
   "source": [
    "## Using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "2bc0a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.373\n",
      "Auc: 0.671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Cluster1       0.45      0.09      0.16        53\n",
      "    Cluster2       0.26      0.31      0.28        45\n",
      "    Cluster3       0.39      0.89      0.54        88\n",
      "    Cluster4       0.43      0.21      0.28        72\n",
      "    Cluster5       0.40      0.04      0.08        48\n",
      "\n",
      "    accuracy                           0.37       306\n",
      "   macro avg       0.39      0.31      0.27       306\n",
      "weighted avg       0.39      0.37      0.30       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "print(\"Auc:\", round(auc,3))\n",
    "print(metrics.classification_report(test_y, y_pred, target_names=\n",
    "                                    ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Cluster5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "7e8e402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 5 15 24  7  2]\n",
      " [ 2 14 26  3  0]\n",
      " [ 1  5 78  3  1]\n",
      " [ 1 11 45 15  0]\n",
      " [ 2  9 28  7  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "ea0f9b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "Cluster3\n",
      "['im 500 mile away home teardrop fell momma note read thing wrote said miss son love come home well didnt pack right back im 500 mile away home away home away home cold tired alone yes im 500 mile away home know road took day left home sure look different guess look different cause time change everything wonder theyll say see boy looking bad oh wonder theyll say get home cant remember ate thumb walk wait im still 500 mile away home luck right id tonight im 500 mile away home away home away home oh im still 500 mile away home']\n"
     ]
    }
   ],
   "source": [
    "loc = random.choice(test_X.index)\n",
    "print(loc)\n",
    "random_test = [test_X[loc]]\n",
    "random_cluster = test_y[loc]\n",
    "print(random_cluster)\n",
    "print(random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "f45a1c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6557)"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf2 = TfidfVectorizer()\n",
    "X_train_tf = tf_idf2.fit_transform(train_X)\n",
    "X_train_tf = tf_idf2.transform(train_X)\n",
    "X_test_tf = tf_idf2.transform(test_X)\n",
    "\n",
    "test_input = tf_idf2.transform(random_test)\n",
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "9092f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 3\n"
     ]
    }
   ],
   "source": [
    "res = naive_bayes_classifier.predict(test_input)[0]\n",
    "if res == 'Cluster1':\n",
    "    print(\"cluster 1\")\n",
    "    \n",
    "elif res == 'Cluster2':\n",
    "    print(\"cluster 2\")\n",
    "    \n",
    "elif res == 'Cluster3':\n",
    "    print(\"cluster 3\")\n",
    "    \n",
    "elif res == 'Cluster4':\n",
    "    print(\"cluster 4\")\n",
    "    \n",
    "elif res == 'Cluster5':\n",
    "    print(\"cluster 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100027d",
   "metadata": {},
   "source": [
    "### Alternative Naive Bayes approach, using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "id": "56d545da",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_train['text_clean'].values\n",
    "y_train = df_train['cluster'].values\n",
    "\n",
    "vec = feature_extraction.text.TfidfVectorizer()\n",
    "vec = vec.fit(corpus)\n",
    "X_names = vec.get_feature_names_out()\n",
    "vec = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "\n",
    "X_train = vec.fit_transform(corpus)\n",
    "dic_vocabulary = vec.vocabulary_\n",
    "\n",
    "classifier = naive_bayes.MultinomialNB()\n",
    "model = pipeline.Pipeline([('vectorizer', vec),('classifier', classifier)])\n",
    "model['classifier'].fit(X_train, y_train)\n",
    "\n",
    "X_test = df_test['text_clean'].values\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3c1bc",
   "metadata": {},
   "source": [
    "#### Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "id": "8ef22d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.373\n",
      "Auc: 0.692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Cluster1       0.45      0.09      0.16        53\n",
      "    Cluster2       0.26      0.31      0.28        45\n",
      "    Cluster3       0.39      0.89      0.54        88\n",
      "    Cluster4       0.43      0.21      0.28        72\n",
      "    Cluster5       0.40      0.04      0.08        48\n",
      "\n",
      "    accuracy                           0.37       306\n",
      "   macro avg       0.39      0.31      0.27       306\n",
      "weighted avg       0.39      0.37      0.30       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(test_y, predicted)\n",
    "auc = metrics.roc_auc_score(test_y, predicted_prob, multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "print(\"Auc:\", round(auc,3))\n",
    "print(metrics.classification_report(test_y, predicted, target_names= \n",
    "                                    ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Cluster5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22be8ff",
   "metadata": {},
   "source": [
    "## Using bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "id": "c223f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10000)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = model_selection.train_test_split(df, test_size=0.2)\n",
    "y_train = df_train['cluster'].values\n",
    "y_test = df_test['cluster'].values\n",
    "\n",
    "vectorizer2 = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "corpus = df_train['text_clean']\n",
    "vectorizer2.fit(corpus)\n",
    "X_train = vectorizer2.transform(corpus)\n",
    "dic_vocabulary = vectorizer2.vocabulary_\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "id": "7df59352",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naive_bayes.MultinomialNB()\n",
    "model = pipeline.Pipeline([('vectorizer', vectorizer2),('classifier', classifier)])\n",
    "model['classifier'].fit(X_train, y_train)\n",
    "\n",
    "X_test = df_test['text_clean'].values\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "ce0f3f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.379\n",
      "Auc: 0.709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Cluster1       1.00      0.06      0.12        31\n",
      "    Cluster2       0.29      0.08      0.12        26\n",
      "    Cluster3       0.39      0.82      0.53        45\n",
      "    Cluster4       0.36      0.53      0.43        32\n",
      "    Cluster5       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.38       153\n",
      "   macro avg       0.41      0.30      0.24       153\n",
      "weighted avg       0.44      0.38      0.29       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "print(\"Auc:\", round(auc,3))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b2933",
   "metadata": {},
   "source": [
    "### Chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "c79bbe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(669, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>ch</td>\n",
       "      <td>0.966676</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>daughter</td>\n",
       "      <td>0.965090</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>rock</td>\n",
       "      <td>0.964756</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>mickey</td>\n",
       "      <td>0.961259</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>kindsa</td>\n",
       "      <td>0.960823</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature     score   cluster\n",
       "1056        ch  0.966676  Cluster1\n",
       "1523  daughter  0.965090  Cluster1\n",
       "6599      rock  0.964756  Cluster1\n",
       "5399    mickey  0.961259  Cluster1\n",
       "4515    kindsa  0.960823  Cluster1"
      ]
     },
     "execution_count": 1148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['cluster']\n",
    "X_names = vectorizer2.get_feature_names_out()\n",
    "p_value_limit = 0.70\n",
    "df_features = pd.DataFrame()\n",
    "for cat in np.unique(y):\n",
    "    chi2, p = feature_selection.chi2(X_train, y==cat)\n",
    "    df_features = df_features.append(pd.DataFrame({'feature':X_names, 'score':1-p, 'cluster':cat}))\n",
    "    df_features = df_features.sort_values(['cluster','score'], ascending=[True,False])\n",
    "    df_features = df_features[df_features['score']>p_value_limit]\n",
    "X_names = df_features['feature'].unique().tolist()\n",
    "\n",
    "print(df_features.shape)\n",
    "df_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "id": "526088e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['cluster'].values\n",
    "\n",
    "vectorizer3 = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
    "vectorizer3.fit(corpus)\n",
    "X_train = vectorizer3.transform(corpus)\n",
    "dic_vocabulary = vectorizer3.vocabulary_\n",
    "\n",
    "classifier = naive_bayes.MultinomialNB()\n",
    "\n",
    "model = pipeline.Pipeline([('vectorizer', vectorizer3), ('classifier', classifier)])\n",
    "model['classifier'].fit(X_train, y_train)\n",
    "\n",
    "X_test = df_test['text_clean'].values\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "id": "d31946b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.379\n",
      "Auc: 0.664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Cluster1       0.33      0.23      0.27        31\n",
      "    Cluster2       0.24      0.27      0.25        26\n",
      "    Cluster3       0.41      0.67      0.50        45\n",
      "    Cluster4       0.48      0.34      0.40        32\n",
      "    Cluster5       0.50      0.16      0.24        19\n",
      "\n",
      "    accuracy                           0.38       153\n",
      "   macro avg       0.39      0.33      0.33       153\n",
      "weighted avg       0.39      0.38      0.36       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "print(\"Auc:\", round(auc,3))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "29c7f62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster1\n",
      "  . selected features: 334\n",
      "  . top features: rock rock, ch, mickey, im back, jenny, lucille, get enough, daughter, gonna rock, rock\n",
      " \n",
      "Cluster2\n",
      "  . selected features: 289\n",
      "  . top features: soul man, wah, good time, sunshine, alfie, im soul, happy birthday, roll baby, hold hold, hear music\n",
      " \n",
      "Cluster3\n",
      "  . selected features: 163\n",
      "  . top features: always something, something remind, wait, prayer, everybody know, pink, daniel, miss, fall piece, angel\n",
      " \n",
      "Cluster4\n",
      "  . selected features: 202\n",
      "  . top features: purple, judy, drug rock, sex drug, jane, mary, eater, purple people, shirley, plug\n",
      " \n",
      "Cluster5\n",
      "  . selected features: 297\n",
      "  . top features: cant cant, fa, personality, fa fa, niggaz, daddy come, aint aint, gloria, fuck, attitude\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for cat in np.unique(y):\n",
    "   print(cat)\n",
    "   print(\"  . selected features:\", len(df_features[df_features['cluster']==cat]))\n",
    "   print(\"  . top features:\", \", \".join(df_features[df_features['cluster']==cat]['feature'].values[:10]))\n",
    "   print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa1407",
   "metadata": {},
   "source": [
    "## Using trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "f7dab6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(df, test_size=0.2)\n",
    "y_train = df_train['cluster'].values\n",
    "y_test = df_test['cluster'].values\n",
    "\n",
    "vectorizer2 = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,3))\n",
    "corpus = df_train['text_clean']\n",
    "vectorizer2.fit(corpus)\n",
    "X_train = vectorizer2.transform(corpus)\n",
    "dic_vocabulary = vectorizer2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "da55697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naive_bayes.MultinomialNB()\n",
    "model = pipeline.Pipeline([('vectorizer', vectorizer2),('classifier', classifier)])\n",
    "model['classifier'].fit(X_train, y_train)\n",
    "\n",
    "X_test = df_test['text_clean'].values\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "id": "771041a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.405\n",
      "Auc: 0.708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Cluster1       1.00      0.10      0.18        31\n",
      "    Cluster2       0.67      0.09      0.15        23\n",
      "    Cluster3       0.38      0.91      0.54        45\n",
      "    Cluster4       0.43      0.42      0.43        38\n",
      "    Cluster5       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.41       153\n",
      "   macro avg       0.50      0.30      0.26       153\n",
      "weighted avg       0.52      0.41      0.32       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "auc = metrics.roc_auc_score(y_test, predicted_prob, multi_class=\"ovr\")\n",
    "print(\"Accuracy:\",  round(accuracy,3))\n",
    "print(\"Auc:\", round(auc,3))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a412e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
